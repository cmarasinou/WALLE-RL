{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be found in the repository\n",
    " https://github.com/cmarasinou/WALLE-RL\n",
    " \n",
    "We build a gridworld environment and agent and use Q-learning to make the agent learn.\n",
    "\n",
    "The environment can be any size and have arbitrary obstacles and terminal states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The transition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transition_model(h,w, \n",
    "                              terminal_state_locs, \n",
    "                              impossible_state_locs, \n",
    "                              p_forward = 0.8, \n",
    "                              actions= np.array([(0,-1),(0,+1),(-1,0),(+1,0)], dtype=int)):\n",
    "    '''Defines the transition matrix for a general Gridworld\n",
    "    Args:\n",
    "        h (int): height of the Gridworld\n",
    "        w (int): width of the Gridworld\n",
    "        terminal_state_locs (np.array of ints, dims: 2 x n_terminal_states): the \n",
    "            locations of the terminal states on the grid  \n",
    "        impossible_state_locs (np.array of ints, dims: 2 x n_impossible_states): the \n",
    "            locations of the interior walls on the grid  \n",
    "        p_forward (float, optional): probability of obeying the action signal and moving forward\n",
    "        actions (np.array of ints, dims: 2 x n_actions, optional): actions operations\n",
    "            on state locations, the default corresponds to [LEFT, RIGHT, DOWN, UP]\n",
    "    \n",
    "    Returns:\n",
    "        P (np.array of floats, dims: n_states x n_actions x n_states): Tensor giving the \n",
    "            transition model P(s',a,s) (with the index order described here)\n",
    "    '''\n",
    "    n_states = h*w\n",
    "    n_actions = len(actions)\n",
    "    \n",
    "    # State locations map\n",
    "    s_locs = np.array([(x,y) for x in range(0,h) for y in range(0,w)])\n",
    "    \n",
    "    terminal_states = [state_index(h,w,l) for l in terminal_state_locs]\n",
    "    impossible_states = [state_index(h,w,l) for l in impossible_state_locs]\n",
    "    \n",
    "    # Initialize to zero\n",
    "    P = np.zeros((n_states, n_actions, n_states))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Generate Transitions\n",
    "    for s in range(n_states):\n",
    "        # For states that can't be reached\n",
    "        if s in impossible_states+terminal_states:\n",
    "                continue\n",
    "        for a in range(n_actions):\n",
    "            sLoc = s_locs[s]\n",
    "            act = actions[a]\n",
    "            act2, act3 = 1-np.abs(act),-(1-np.abs(act))\n",
    "            acts = (act,act2,act3)\n",
    "            probs = (p_forward, (1-p_forward)/2.,(1-p_forward)/2.)\n",
    "            for aa, pp in zip(acts, probs):\n",
    "                spLoc = sLoc+aa\n",
    "                if out_of_bounds(h,w,spLoc, impossible_states):\n",
    "                    spLoc = sLoc\n",
    "                sp = state_index(h,w,spLoc)\n",
    "                P[sp,a,s] += pp\n",
    "    \n",
    "    return P\n",
    "\n",
    "def out_of_bounds(h,w,state_location, impossible_states):\n",
    "    '''Determines whether given state out of bounds'''\n",
    "    if state_location[0] in range(0,h) and state_location[1] in range(0,w):\n",
    "        if state_index(h,w,state_location) in impossible_states:\n",
    "            return True\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "    \n",
    "def state_index(h,w,s_loc):\n",
    "    '''Maps a state location (tuple) to the state value (integer)'''\n",
    "    return s_loc[0]*w+s_loc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the transition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 3, 4\n",
    "terminalStates = np.array([(2,3),(1,3)],dtype=int)\n",
    "wallStates = np.array([(1,1)], dtype=int)\n",
    "Ptest = generate_transition_model(height,width,terminalStates, wallStates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum of propabilities check. Summing over s'\n",
    "Ptest.sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than the terminal and wall states we get probability to sum up to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv():\n",
    "    '''Creates a Gridworld environment\n",
    "    Args:\n",
    "        h (int): height of the Gridworld\n",
    "        w (int): width of the Gridworld\n",
    "        rewards_matrix (np.array of floats, dims: h x w)\n",
    "        terminal_state_locs (np.array of ints, dims: 2 x n_terminal_states): the \n",
    "            locations of the terminal states on the grid  \n",
    "        impossible_state_locs (np.array of ints, dims: 2 x n_impossible_states): the \n",
    "            locations of the interior walls on the grid  \n",
    "        p_forward (float, optional): probability of obeying the action signal and moving forward\n",
    "        actions (np.array of ints, dims: 2 x n_actions, optional): actions operations\n",
    "            on state locations, the default corresponds to [LEFT, RIGHT, DOWN, UP]\n",
    "        initial_state (int or str, optional): state at which environment is initialized\n",
    "            can be int corresponding to number of state or str='random'\n",
    "    '''\n",
    "    def __init__(self,h,w, \n",
    "                 rewards_matrix, \n",
    "                 terminal_state_locs, \n",
    "                 impossible_state_locs, \n",
    "                 p_forward=0.8,\n",
    "                 actions=np.array([(0,-1),(0,+1),(-1,0),(+1,0)], dtype=int),\n",
    "                 initial_state=0):\n",
    "\n",
    "        self.n_states = h*w\n",
    "        self.h = h # world height\n",
    "        self.w = w #world width\n",
    "        \n",
    "        # define states\n",
    "        self.initial_state = initial_state \n",
    "        self.current_state= initial_state\n",
    "        self.s_locs = np.array([(x,y) for x in range(0,h) for y in range(0,w)])\n",
    "        self.states = [state_index(h,w,l) for l in self.s_locs]\n",
    "        self.terminal_state_locs = terminal_state_locs\n",
    "        self.impossible_state_locs = impossible_state_locs\n",
    "        self.terminal_states = [state_index(h,w,l) for l in terminal_state_locs]\n",
    "        self.impossible_states = [state_index(h,w,l) for l in impossible_state_locs]\n",
    "\n",
    "        self.regular_states = self.states.copy()\n",
    "        for s in self.terminal_states+self.impossible_states:\n",
    "            self.regular_states.remove(s)\n",
    "        if initial_state == 'random':\n",
    "            self.current_state = random.choice(self.regular_states)\n",
    "        \n",
    "        # define actions\n",
    "        self.n_actions = len(actions)\n",
    "        self.actions = actions\n",
    "        \n",
    "        # define rewards\n",
    "        self.rewards = rewards_matrix.ravel()\n",
    "        self.initial_reward = self.rewards[self.current_state]\n",
    "        \n",
    "        # define transition model\n",
    "        self.p_forward = p_forward\n",
    "        self.transition_model = generate_transition_model(h,w, \n",
    "                                                          terminal_state_locs, \n",
    "                                                          impossible_state_locs,\n",
    "                                                          p_forward)\n",
    "\n",
    "        \n",
    "    def step(self, a):\n",
    "        '''Performs a transition given an action\n",
    "            a (int): the action's index\n",
    "        Returns:\n",
    "            current_state (int)\n",
    "            reward (float)\n",
    "            Bool: If True episode finished and environment re-initialized\n",
    "        '''\n",
    "        # transition to new state\n",
    "        self.current_state = np.random.choice(self.n_states, \n",
    "                     p=self.transition_model[:,a,self.current_state])\n",
    "        if self.current_state in self.terminal_states:\n",
    "            end_state = self.current_state\n",
    "            reward = self.rewards[end_state]\n",
    "            #Reinitialize\n",
    "            if self.initial_state == 'random':\n",
    "                self.current_state = random.choice(self.regular_states)\n",
    "            else:\n",
    "                self.current_state = self.initial_state\n",
    "            return end_state, reward, True # Last bool indicates that episode finished\n",
    "                \n",
    "        return self.current_state, self.rewards[self.current_state], False     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 3, 4\n",
    "terminalStates = np.array([(2,3),(1,3)],dtype=int)\n",
    "wallStates = np.array([(1,1)], dtype=int)\n",
    "rewardsMatrix = np.array([ (-0.04, -0.04, -0.04, -0.04),\n",
    "                           (-0.04,  0.0,  -0.04, -1.0),\n",
    "                           (-0.04, -0.04, -0.04,  1.0)])\n",
    "\n",
    "env = GridWorldEnv(3,4, rewardsMatrix, terminalStates,  wallStates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, -0.04, False)\n",
      "(2, -0.04, False)\n",
      "(3, -0.04, False)\n",
      "(3, -0.04, False)\n",
      "(3, -0.04, False)\n"
     ]
    }
   ],
   "source": [
    "# Applying many consecutive actions\n",
    "for i in range(0,5):\n",
    "    print(env.step(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment responds. Episodes can be terminated and environment resets.\n",
    "\n",
    "Let's check on the map of the states and state locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, -1],\n",
       "       [ 0,  1],\n",
       "       [-1,  0],\n",
       "       [ 1,  0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [0, 2],\n",
       "       [0, 3],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 3],\n",
       "       [2, 0],\n",
       "       [2, 1],\n",
       "       [2, 2],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.s_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. The Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldAgent():\n",
    "    '''Creates a Gridworld agent\n",
    "    Args:\n",
    "        policy_matrix (np.array of ints, dims: h x w): the initial policy \n",
    "        actions (np.array of ints, dims: 2 x n_actions, optional): actions operations\n",
    "            on state locations, the default corresponds to [LEFT, RIGHT, DOWN, UP]\n",
    "        action_symbols (np.array of ints, dims: 1 x n_actions, optional):\n",
    "            corresponding action symbols for rendering\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 policy_matrix, \n",
    "                 actions=np.array([(0,-1),(0,+1),(-1,0),(+1,0)]),\n",
    "                 action_symbols = np.array(['<','>','^','v']),\n",
    "                ):\n",
    "        \n",
    "        #define actions\n",
    "        self.n_actions = len(actions)\n",
    "        self.actions = actions\n",
    "        self.action_symbols = action_symbols\n",
    "        \n",
    "        # Defining policy\n",
    "        if policy_matrix.dtype==int:\n",
    "            self.policy = policy_matrix.ravel()\n",
    "        else:\n",
    "            # when policy is given in symbol notation\n",
    "            self.policy = self.translate_policy(policy_matrix)\n",
    "        self.h, self.w = policy_matrix.shape\n",
    "        \n",
    "    def translate_policy(self,policy_symbols_matrix):\n",
    "        '''Gets policy in symbols. Outputs policy as array of integers'''\n",
    "        policy_symbols = policy_symbols_matrix.ravel()\n",
    "        policy = np.zeros_like(policy_symbols, dtype=int)\n",
    "        for i, symbol in enumerate(policy_symbols):\n",
    "            if symbol is None:\n",
    "                policy[i] = -1\n",
    "            else:\n",
    "                policy[i] = np.argmax(self.action_symbols==symbol)\n",
    "\n",
    "        return policy\n",
    "\n",
    "    def render_policy(self, mask_states = [], custom_policy = None):\n",
    "        '''Prints symbolic version of current policy'''\n",
    "        if custom_policy is not None:\n",
    "            policy_to_render = custom_policy\n",
    "        else:\n",
    "            policy_to_render = self.policy\n",
    "        policy_render = [self.action_symbols[idx] if idx in range(0,len(self.actions)) else '*'\\\n",
    "                    for idx in policy_to_render]\n",
    "        if mask_states is not None:\n",
    "            for state in mask_states:\n",
    "                policy_render[state] = '*'\n",
    "        policy_render = np.array(policy_render).reshape(self.h,self.w)\n",
    "        print(policy_render)\n",
    "        print('\\n')\n",
    "    \n",
    "    def step(self, state, epsilon = None):\n",
    "        '''Agent decides an action given a policy\n",
    "        Args:\n",
    "            state (int)\n",
    "            epsilon (float, optional, 0.0-1.0): greediness\n",
    "        Returns:\n",
    "            action (int)\n",
    "        '''\n",
    "        action = self.policy[state]\n",
    "        if epsilon is not None:\n",
    "            sigma = random.random()\n",
    "            if sigma <= epsilon:\n",
    "                # choose action randomly\n",
    "                actions = list(range(0,self.n_actions))\n",
    "                actions.remove(action)\n",
    "                action = random.choice(actions)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_matrix = np.zeros((3,4),dtype=int)\n",
    "agent = GridWorldAgent(policy_matrix)\n",
    "agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<' '<' '<' '<']\n",
      " ['<' '<' '<' '<']\n",
      " ['<' '<' '<' '<']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent.render_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  0,  0,  0,  3, -1,  3, -1,  1,  1,  1, -1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_symbols = np.array([['v' ,'<', '<' ,'<'],\n",
    "                           ['v', None ,'v', None],\n",
    "                           ['>' ,'>', '>', None]])\n",
    "agent = GridWorldAgent(policy_symbols)\n",
    "agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.step(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['v' '<' '<' '<']\n",
      " ['v' '*' 'v' '*']\n",
      " ['>' '>' '>' '*']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent.render_policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    '''Initializes agent, environment\n",
    "    '''\n",
    "    h, w = 3,4\n",
    "    n_states = h*w\n",
    "    n_actions = 4\n",
    "    terminalStates = np.array([(2,3),(1,3)],dtype=int)\n",
    "    wallStates = np.array([(1,1)], dtype=int)\n",
    "    rewardsMatrix = np.array([ (-0.04, -0.04, -0.04, -0.04),\n",
    "                               (-0.04,  0.0,  -0.04, -1.0),\n",
    "                               (-0.04, -0.04, -0.04,  1.0)])\n",
    "    q = np.zeros((n_states,n_actions))\n",
    "    policy_matrix = np.random.randint(0,4,(3,4),dtype=int)\n",
    "    agent = GridWorldAgent(policy_matrix)\n",
    "    env = GridWorldEnv(3,4, rewardsMatrix, terminalStates,  wallStates, initial_state='random', p_forward=0.8)\n",
    "    state = env.current_state\n",
    "    reward = env.initial_reward\n",
    "    episode_finished=False\n",
    "    return agent, env, state, reward, episode_finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def update_q(q, alpha, gamma, s, a, rp, sp):\n",
    "    '''Applying q-learning update\n",
    "    Args:\n",
    "        q (np.array of floats, dims: n_states x n_actions) \n",
    "    Returns:\n",
    "        q (np.array of floats, dims: n_states x n_actions): updated q\n",
    "    '''\n",
    "    q[s, a] = q[s, a]+alpha*(rp+gamma*q[sp,:].max()- q[s, a])\n",
    "    return q\n",
    "\n",
    "def update_policy(q):\n",
    "    '''Given the q-matrix gives back the policy\n",
    "    Args:\n",
    "        q (np.array of floats, dims: n_states x n_actions) \n",
    "    Returns:\n",
    "        policy (np.array of ints, dims: n_states): ints represent actions\n",
    "    '''\n",
    "    policy = q.argmax(axis = 1)\n",
    "    return policy\n",
    "\n",
    "def qlearning(convergence_criterion = 30000, alpha=0.1, gamma=0.999, epsilon=None):\n",
    "    '''Performs qlearning\n",
    "    Args:\n",
    "        convergence_criterion (int, optional): number of iterations policy should\n",
    "            stay the same for algorithm to finish\n",
    "        alpha (float, optional)\n",
    "        gamma (float, optional)\n",
    "        epsilon (float, optional)\n",
    "    Returns:\n",
    "        agent and q_values\n",
    "    '''\n",
    "    n_iters = 0\n",
    "    same_policy_iter = 0\n",
    "    n_episodes = 0\n",
    "    q = np.zeros((12,4))\n",
    "    q_values = list()\n",
    "    agent, env, s, r, episode_finished = initialize()\n",
    "    no_action_states = env.impossible_states + env.terminal_states\n",
    "    print('Iteration {} ---- Current policy same for {} iterations'.format(n_iters, same_policy_iter))\n",
    "    agent.render_policy(mask_states=no_action_states)\n",
    "    while same_policy_iter < convergence_criterion:\n",
    "        a = agent.step(s, epsilon=epsilon)\n",
    "        sp, rp, episode_finished = env.step(a)\n",
    "        q = update_q(q, alpha, gamma, s, a, rp, sp)\n",
    "        previous_policy = agent.policy\n",
    "\n",
    "        agent.policy = update_policy(q)\n",
    "        s, r = sp, rp\n",
    "        current_policy = agent.policy\n",
    "        \n",
    "        #previous_policy = previous_policy.ravel()\n",
    "        #previous_policy[no_action_states] = 0\n",
    "        #current_policy = current_policy.ravel()\n",
    "        #current_policy[no_action_states] = 0\n",
    "    \n",
    "        \n",
    "        if np.array_equal(previous_policy, agent.policy):\n",
    "            same_policy_iter += 1\n",
    "        else:\n",
    "            same_policy_iter = 0\n",
    "        n_iters += 1\n",
    "        q_values.append(q.mean())\n",
    "        if n_iters%50000 == 0:\n",
    "            print('Iteration {} ---- Current policy same for {} iterations'.format(n_iters, same_policy_iter))\n",
    "            agent.render_policy(mask_states=no_action_states)\n",
    "        if episode_finished:\n",
    "            n_episodes += 1\n",
    "            s, r = env.current_state, env.initial_reward\n",
    "    print('Final iteration number {}'.format(n_iters))\n",
    "    print('Final policy')\n",
    "    agent.render_policy(mask_states=no_action_states)\n",
    "    return agent, q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 ---- Current policy same for 0 iterations\n",
      "[['>' '^' '<' 'v']\n",
      " ['^' '*' '<' '*']\n",
      " ['^' '>' '^' '*']]\n",
      "\n",
      "\n",
      "Final iteration number 30907\n",
      "Final policy\n",
      "[['v' '>' 'v' '<']\n",
      " ['v' '*' 'v' '*']\n",
      " ['>' '>' '>' '*']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent,q_values = qlearning(epsilon=0.005, alpha=0.05, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.scatter(range(0,len(q_values)),q_values)\n",
    "plt.title('Q mean value')\n",
    "plt.xlabel('n_iteration')\n",
    "plt.ylabel('mean(q)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
